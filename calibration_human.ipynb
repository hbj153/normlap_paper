{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed647200-c66f-4e64-9f79-4a9b6a2106f9",
   "metadata": {},
   "source": [
    "calibrate overlap between human networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e4281de-fc6e-484d-93f9-a4a1535a1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calibration\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "from itertools import combinations\n",
    "import random\n",
    "import os\n",
    "from scipy import stats\n",
    "import sys\n",
    "from matplotlib import cm\n",
    "from tqdm import trange\n",
    "import seaborn as sns\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c62e2cc-e951-43ff-8142-e827a9174c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_elist(elist,selfLink=False):\n",
    "    '''\n",
    "    selfLink: if False, the returned edgelist will not include self-interactions.\n",
    "    '''\n",
    "    if len(elist)==0 or type(elist[0][0])!=str: return list(set(sorted([tuple(sorted(x)) for x in elist])))\n",
    "\n",
    "    if selfLink==False:\n",
    "        res = list(set(sorted([tuple(sorted(pair)) for pair in elist if ('ENSG' in pair[0]) and ('ENSG' in pair[1]) and(pair[0]!=pair[1]) ])))\n",
    "    else:\n",
    "        res = list(set(sorted([tuple(sorted(pair)) for pair in elist if ('ENSG' in pair[0]) and ('ENSG' in pair[1]) ])))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019416c-9783-467a-8115-b47cdcf4cc76",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc3d4b7-9374-4d29-8178-c0586d989156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_litbm = pd.read_csv('datasets/human/Lit-BM/Lit-BM_huri.tsv',sep='\\t',header=None).astype(str)\n",
    "litbmE = sort_elist(df_litbm.values)\n",
    "\n",
    "df_bioplex = pd.read_csv('datasets/human/BioPlex/BioPlex3_processed.txt').astype(str)\n",
    "bioplexE = sort_elist(df_bioplex.values)\n",
    "\n",
    "df_qubic = pd.read_csv('datasets/human/Qubic/Qubic_processed.txt').astype(str)\n",
    "qubicE = sort_elist(df_qubic.values)\n",
    "\n",
    "df_huri = pd.read_csv('datasets/human/HuRI/[original]HuRI.tsv',sep='\\t').astype(str)\n",
    "huriE = sort_elist(df_huri.values)\n",
    "\n",
    "df_huriPSN = pd.read_csv('datasets/human/HuRI-PSN/HuRI-PSN02_processed.txt').astype(str)\n",
    "huriPSNE = sort_elist(df_huriPSN.values)\n",
    "df_ccsb = pd.read_csv('datasets/human/CCSB/Supplementary Table 11.txt',sep='\\t')\n",
    "\n",
    "df_rual = df_ccsb[df_ccsb.in_Rual==1].iloc[:,:2].astype(str)\n",
    "rualE = sort_elist(df_rual.values)\n",
    "\n",
    "df_ven = df_ccsb[df_ccsb.in_Venkatesan==1].iloc[:,:2].astype(str)\n",
    "venE = sort_elist(df_ven.values)\n",
    "\n",
    "df_yu = df_ccsb[df_ccsb.in_Yu==1].iloc[:,:2].astype(str)\n",
    "yuE = sort_elist(df_yu.values)\n",
    "\n",
    "df_rolland = df_ccsb[df_ccsb.in_Rolland==1].iloc[:,:2].astype(str)\n",
    "rollandE = sort_elist(df_rolland.values)\n",
    "\n",
    "df_yang = df_ccsb[df_ccsb.in_Yang==1].iloc[:,:2].astype(str)\n",
    "yangE = sort_elist(df_yang.values)\n",
    "\n",
    "df_i3d = pd.read_csv('datasets/human/I3D/I3D_processed.txt')\n",
    "i3dE = sort_elist(df_i3d.values)\n",
    "\n",
    "df_string900 = pd.read_csv('datasets/human/STRING/STRING_physical_threshold900.txt')\n",
    "string900E = sort_elist(df_string900.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c48c1a-5c41-4608-98ca-0db2d0929234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: 4229, links: 33125\n"
     ]
    }
   ],
   "source": [
    "# check nodes and links\n",
    "test = huriPSNE\n",
    "print(\"node: %s, links: %s\"%(len(set(np.array(test).flatten())),len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802690e-16e3-450c-a8fc-8ed0c8d074b9",
   "metadata": {},
   "source": [
    "# All by all network of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7312ab01-ec12-4a79-9856-2c55643bbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['HuRI','HI-I-05','Venkatesan-09','HI-II-14','Yang-16','Yu-11','Lit-BM-17','STRING(HsC)-H','I3D-H','BioPlex','Qubic','HuRI-PSN']\n",
    "dictElist = {'HuRI':huriE,'HI-I-05':rualE,'Venkatesan-09':venE,'HI-II-14':rollandE,'Yang-16':yangE,'Yu-11':yuE,\n",
    "             'Lit-BM-17':litbmE,'STRING(HsC)-H':string900E,'I3D-H':i3dE,\n",
    "             'BioPlex':bioplexE,'Qubic':qubicE,\n",
    "             'HuRI-PSN':huriPSNE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5777ba-0838-4c47-bafb-8fde93fea1c3",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1fa3863-0b75-49e8-adae-3b32ebdce0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 389 ms, sys: 10.5 ms, total: 399 ms\n",
      "Wall time: 401 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>nodes</th>\n",
       "      <th>links</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuRI</td>\n",
       "      <td>8245</td>\n",
       "      <td>52067</td>\n",
       "      <td>0.001532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rual</td>\n",
       "      <td>1500</td>\n",
       "      <td>2561</td>\n",
       "      <td>0.002278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venkatesan</td>\n",
       "      <td>195</td>\n",
       "      <td>187</td>\n",
       "      <td>0.009886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rolland</td>\n",
       "      <td>4111</td>\n",
       "      <td>13118</td>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yang</td>\n",
       "      <td>502</td>\n",
       "      <td>717</td>\n",
       "      <td>0.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yu</td>\n",
       "      <td>1133</td>\n",
       "      <td>1127</td>\n",
       "      <td>0.001757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lit-BM-17</td>\n",
       "      <td>5956</td>\n",
       "      <td>12758</td>\n",
       "      <td>0.000719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>STRING(HsC)-H</td>\n",
       "      <td>6662</td>\n",
       "      <td>39567</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I3D-H</td>\n",
       "      <td>3155</td>\n",
       "      <td>4354</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BioPlex</td>\n",
       "      <td>12408</td>\n",
       "      <td>97078</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qubic</td>\n",
       "      <td>4927</td>\n",
       "      <td>23848</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HuRI-PSN</td>\n",
       "      <td>4229</td>\n",
       "      <td>33125</td>\n",
       "      <td>0.003705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  nodes  links   density\n",
       "0            HuRI   8245  52067  0.001532\n",
       "1            Rual   1500   2561  0.002278\n",
       "2      Venkatesan    195    187  0.009886\n",
       "3         Rolland   4111  13118  0.001553\n",
       "4            Yang    502    717  0.005702\n",
       "5              Yu   1133   1127  0.001757\n",
       "6       Lit-BM-17   5956  12758  0.000719\n",
       "7   STRING(HsC)-H   6662  39567  0.001783\n",
       "8           I3D-H   3155   4354  0.000875\n",
       "9         BioPlex  12408  97078  0.001261\n",
       "10          Qubic   4927  23848  0.001965\n",
       "11       HuRI-PSN   4229  33125  0.003705"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "for label in labels:\n",
    "    test = dictElist[label]\n",
    "    res.append([label,len(set(np.array(test).flatten())),len(test)])\n",
    "df_stat = pd.DataFrame(res,columns=['dataset','nodes','links'])\n",
    "n = df_stat['nodes']\n",
    "l = df_stat['links']\n",
    "density = l/(n*(n-1)/2)\n",
    "df_stat['density'] = density\n",
    "df_stat.to_csv('results human/dataset_overview.txt',index=False)\n",
    "df_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c2366",
   "metadata": {},
   "source": [
    "## All by all - optimize pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482a6b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [2:19:39<00:00, 126.96s/it]  \n"
     ]
    }
   ],
   "source": [
    "df_preRes = pd.DataFrame()\n",
    "testedPairs = [(row[0],row[1]) for row in df_preRes.values]+[(row[1],row[0]) for row in df_preRes.values]\n",
    "allPairs = list(combinations(labels,2))\n",
    "results = []\n",
    "s = time.time()\n",
    "for i in trange(len(allPairs)):\n",
    "    pair = allPairs[i]\n",
    "    if pair in testedPairs: continue # if the pair has been calculated, skip it.\n",
    "    pos1_mean, pos1_sigma, cur_iter1 = calibration.random_subnetwork.optimize_pos(dictElist[pair[0]],dictElist[pair[1]])\n",
    "    pos2_mean, pos2_sigma, cur_iter2 = calibration.random_subnetwork.optimize_pos(dictElist[pair[1]],dictElist[pair[0]])\n",
    "    results.append([pair[0],pair[1],pos1_mean, pos1_sigma, cur_iter1, pos2_mean, pos2_sigma, cur_iter2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results,columns=['A','B','pos1_mean', 'pos1_sigma', 'cur_iter1', 'pos2_mean', 'pos2_sigma', 'cur_iter2'])\n",
    "df_results.to_csv('results human/all_by_all_pos.txt',float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c2366",
   "metadata": {},
   "source": [
    "## All by all - optimize neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482a6b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [36:57<00:00, 33.60s/it] \n"
     ]
    }
   ],
   "source": [
    "df_preRes = pd.DataFrame()\n",
    "testedPairs = [(row[0],row[1]) for row in df_preRes.values]+[(row[1],row[0]) for row in df_preRes.values]\n",
    "allPairs = list(combinations(labels,2))\n",
    "results = []\n",
    "s = time.time()\n",
    "for i in trange(len(allPairs)):\n",
    "    pair = allPairs[i]\n",
    "    if pair in testedPairs: continue # if the pair has been calculated, skip it.\n",
    "    neg1_mean, neg1_sigma, cur_iter1 = calibration.random_network.optimize_neg(dictElist[pair[0]],dictElist[pair[1]])\n",
    "    neg2_mean, neg2_sigma, cur_iter2 = calibration.random_network.optimize_neg(dictElist[pair[1]],dictElist[pair[0]])\n",
    "    results.append([pair[0],pair[1],neg1_mean, neg1_sigma, cur_iter1, neg2_mean, neg2_sigma, cur_iter2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b9f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results,columns=['A','B','neg1_mean', 'neg1_sigma', 'cur_iter1', 'neg2_mean', 'neg2_sigma', 'cur_iter2'])\n",
    "df_results.to_csv('results human/all_by_all_neg.txt',float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d043f",
   "metadata": {},
   "source": [
    "## Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "df_pos = pd.read_csv('results/all_by_all_pos.txt')\n",
    "df_neg = pd.read_csv('results/all_by_all_neg.txt')\n",
    "df = pd.merge(df_pos,df_neg,on=['A','B'])\n",
    "\n",
    "# select neg benchmark\n",
    "z_neg1 = [abs((obs-neg1_mean)/neg1_sigma) if neg1_sigma != 0 else np.nan for obs,\n",
    "          neg1_mean, neg1_sigma in zip(df['obs'], df['neg1_mean'], df['neg1_sigma'])]\n",
    "z_neg2 = [abs((obs-neg2_mean)/neg2_sigma) if neg2_sigma != 0 else np.nan for obs,\n",
    "          neg2_mean, neg2_sigma in zip(df['obs'], df['neg2_mean'], df['neg2_sigma'])]\n",
    "df['selected_neg'] = [neg1 if z1 < z2 else neg2 for z1, z2, neg1,\n",
    "                      neg2 in zip(z_neg1, z_neg2, df['neg1_mean'], df['neg2_mean'])]\n",
    "df['selected_neg_sigma'] = [neg1 if z1 < z2 else neg2 for z1, z2, neg1,\n",
    "                            neg2 in zip(z_neg1, z_neg2, df['neg1_sigma'], df['neg2_sigma'])]\n",
    "\n",
    "# select pos benchmark\n",
    "z_pos1 = [abs((obs-pos1_mean)/pos1_sigma) if pos1_sigma != 0 else np.nan for obs,\n",
    "          pos1_mean, pos1_sigma in zip(df['obs'], df['pos1_mean'], df['pos1_sigma'])]\n",
    "z_pos2 = [abs((obs-pos2_mean)/pos2_sigma) if pos2_sigma != 0 else np.nan for obs,\n",
    "          pos2_mean, pos2_sigma in zip(df['obs'], df['pos2_mean'], df['pos2_sigma'])]\n",
    "df['selected_pos'] = [pos1 if z1 < z2 else pos2 for z1, z2, pos1,\n",
    "                      pos2 in zip(z_pos1, z_pos2, df['pos1_mean'], df['pos2_mean'])]\n",
    "df['selected_pos_sigma'] = [pos1 if z1 < z2 else pos2 for z1, z2, pos1,\n",
    "                            pos2 in zip(z_pos1, z_pos2, df['pos1_sigma'], df['pos2_sigma'])]\n",
    "\n",
    "score,score_sigma = calibration.cal_score(df['obs'],df['selected_neg'],df['selected_neg_sigma'],df['selected_pos'],df['selected_pos_sigma'])\n",
    "df['score'] = score\n",
    "df['score_sigma'] = score_sigma\n",
    "neg_z = [(obs-neg_mean)/neg_sigma if neg_sigma!=0 else np.nan for obs,neg_mean,neg_sigma in zip(df['obs'],df['selected_neg'],df['selected_neg_sigma'])]\n",
    "df['neg_p'] = scipy.stats.norm.sf(neg_z)\n",
    "pos_z = [(obs-pos_mean)/pos_sigma if pos_sigma!=0 else np.nan for obs,pos_mean,pos_sigma in zip(df['obs'],df['selected_pos'],df['selected_pos_sigma'])]\n",
    "df['pos_p'] = 1-scipy.stats.norm.sf(pos_z)\n",
    "df['pos_p_binary'] = [1 if (pos_p>=0.05 and neg_p<0.05) else 0 for neg_p,pos_p in zip(df['neg_p'],df['pos_p'])]\n",
    "df.round(3).to_csv(\"results human/all_by_all_networks_no_instance.txt\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1160c08dbd3a0efa4dfb23c557a575e7f836893f449d04d0cc510429b3e8085"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
